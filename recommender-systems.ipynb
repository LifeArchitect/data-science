{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook seeks to explore various techniques for implementing recommender systems, namely\n\n* Popularity-based - recommend items with high rating \n    * weighted mean item ratings\n    * trending, last-watched\n    \n    \n* Content-based - recommend similar items\n    * Cosine similarity of item metadata \n    \n    \n* Collaborative Filtering - recommend items that similar users also like\n    * Matrix Factorization\n    * Nearest Neighbours\n    * Deep learning approaches\n    \n\nOther Challenges\n* Cold-Start Problem\n* Efficiency vs Accuracy"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# To create plots\nimport matplotlib.pyplot as plt\n\n# To create interactive plots\nfrom plotly.offline import init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\n# To shift lists\nfrom collections import deque\n\n# To compute similarities between vectors\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# To use recommender systems\nimport surprise as sp\nfrom surprise.model_selection import cross_validate\n\n# To create deep learning models\nfrom keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\nfrom keras.models import Model\n\n# To create sparse matrices\nfrom scipy.sparse import coo_matrix\n\n# To light fm\nfrom lightfm import LightFM\nfrom lightfm.evaluation import precision_at_k\n\n# To stack sparse matrices\nfrom scipy.sparse import vstack\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"stream","text":"/kaggle/input/the-movies-dataset/links.csv\n/kaggle/input/the-movies-dataset/ratings_small.csv\n/kaggle/input/the-movies-dataset/links_small.csv\n/kaggle/input/the-movies-dataset/credits.csv\n/kaggle/input/the-movies-dataset/ratings.csv\n/kaggle/input/the-movies-dataset/movies_metadata.csv\n/kaggle/input/the-movies-dataset/keywords.csv\n/kaggle/input/netflix-prize-data/qualifying.txt\n/kaggle/input/netflix-prize-data/probe.txt\n/kaggle/input/netflix-prize-data/movie_titles.csv\n/kaggle/input/netflix-prize-data/combined_data_3.txt\n/kaggle/input/netflix-prize-data/combined_data_2.txt\n/kaggle/input/netflix-prize-data/README\n/kaggle/input/netflix-prize-data/combined_data_1.txt\n/kaggle/input/netflix-prize-data/combined_data_4.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Dataset Preprocessing\n\nLets start by using the Netflix prize datasets\n* 17K+ Movies\n* Descriptions of each movie\n* 24M movie ratings from users"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data for all movies\nmovie_titles = pd.read_csv('../input/netflix-prize-data/movie_titles.csv', \n                           encoding = 'ISO-8859-1', \n                           header = None, \n                           names = ['Id', 'Year', 'Name']).set_index('Id')\n\nprint('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\nmovie_titles.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"Shape Movie-Titles:\t(17770, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"      Year                          Name\nId                                      \n1   2003.0               Dinosaur Planet\n2   2004.0    Isle of Man TT 2004 Review\n3   1997.0                     Character\n4   1994.0  Paula Abdul's Get Up & Dance\n5   2004.0      The Rise and Fall of ECW","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Name</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2003.0</td>\n      <td>Dinosaur Planet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2004.0</td>\n      <td>Isle of Man TT 2004 Review</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1997.0</td>\n      <td>Character</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1994.0</td>\n      <td>Paula Abdul's Get Up &amp; Dance</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2004.0</td>\n      <td>The Rise and Fall of ECW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load a movie metadata dataset\nmovie_metadata = pd.read_csv('../input/the-movies-dataset/movies_metadata.csv', low_memory=False)[['original_title', 'overview', 'vote_count']].set_index('original_title').dropna()\n# Remove the long tail of rarly rated moves\nmovie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n\nprint('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\nmovie_metadata.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"Shape Movie-Metadata:\t(21604, 1)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                                                      overview\noriginal_title                                                                \nToy Story                    Led by Woody, Andy's toys live happily in his ...\nJumanji                      When siblings Judy and Peter discover an encha...\nGrumpier Old Men             A family wedding reignites the ancient feud be...\nWaiting to Exhale            Cheated on, mistreated and stepped on, the wom...\nFather of the Bride Part II  Just when George Banks has recovered from his ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overview</th>\n    </tr>\n    <tr>\n      <th>original_title</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Toy Story</th>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n    </tr>\n    <tr>\n      <th>Jumanji</th>\n      <td>When siblings Judy and Peter discover an encha...</td>\n    </tr>\n    <tr>\n      <th>Grumpier Old Men</th>\n      <td>A family wedding reignites the ancient feud be...</td>\n    </tr>\n    <tr>\n      <th>Waiting to Exhale</th>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n    </tr>\n    <tr>\n      <th>Father of the Bride Part II</th>\n      <td>Just when George Banks has recovered from his ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load single data-file\ndf_raw = pd.read_csv('../input/netflix-prize-data/combined_data_1.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n\n# Find empty rows to slice dataframe for each movie\ntmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\nmovie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n\n# Shift the movie_indices by one to get start and endpoints of all movies\nshifted_movie_indices = deque(movie_indices)\nshifted_movie_indices.rotate(-1)\nuser_data = []\n\n# Iterate over all movies \nfor [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n    if df_id_1<df_id_2: # Check if it is the last movie in the file\n        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n    else:\n        tmp_df = df_raw.loc[df_id_1+1:].copy()\n        \n    # Create movie_id column and append df\n    tmp_df['Movie'] = movie_id\n    user_data.append(tmp_df)\n\n# Combine all dataframes\ndf = pd.concat(user_data)\ndel user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\nprint('Shape User-Ratings:\\t{}'.format(df.shape))\ndf.sample(5)","execution_count":4,"outputs":[{"output_type":"stream","text":"Shape User-Ratings:\t(24053764, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"             User  Rating        Date  Movie\n15320052  1437491     5.0  2005-06-19   2942\n13748072  1585984     4.0  2003-06-08   2617\n11701589  1582756     5.0  2005-06-19   2212\n15339400  1497697     4.0  2005-09-01   2944\n5783496   1289706     3.0  2005-06-10   1145","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Rating</th>\n      <th>Date</th>\n      <th>Movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15320052</th>\n      <td>1437491</td>\n      <td>5.0</td>\n      <td>2005-06-19</td>\n      <td>2942</td>\n    </tr>\n    <tr>\n      <th>13748072</th>\n      <td>1585984</td>\n      <td>4.0</td>\n      <td>2003-06-08</td>\n      <td>2617</td>\n    </tr>\n    <tr>\n      <th>11701589</th>\n      <td>1582756</td>\n      <td>5.0</td>\n      <td>2005-06-19</td>\n      <td>2212</td>\n    </tr>\n    <tr>\n      <th>15339400</th>\n      <td>1497697</td>\n      <td>4.0</td>\n      <td>2005-09-01</td>\n      <td>2944</td>\n    </tr>\n    <tr>\n      <th>5783496</th>\n      <td>1289706</td>\n      <td>3.0</td>\n      <td>2005-06-10</td>\n      <td>1145</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For effecient performance reasons, we want to only get the top 500 movies for this demonstration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter sparse movies\nmin_movie_ratings = 10000\nfilter_movies = (df['Movie'].value_counts()>min_movie_ratings)\nfilter_movies = filter_movies[filter_movies].index.tolist()\n\n# Filter sparse users\nmin_user_ratings = 200\nfilter_users = (df['User'].value_counts()>min_user_ratings)\nfilter_users = filter_users[filter_users].index.tolist()\n\n# Filter all users and movies with low rating count (not useful to us) ~ 4M ratings\ndf_filterd = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\ndel filter_movies, filter_users, min_movie_ratings, min_user_ratings\nprint('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\nprint('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))","execution_count":5,"outputs":[{"output_type":"stream","text":"Shape User-Ratings unfiltered:\t(24053764, 4)\nShape User-Ratings filtered:\t(4178032, 4)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle df and Split into training and testing data \ndf_filterd = df_filterd.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\ntest_size = 100000\ndf_train = df_filterd[:-test_size]\ndf_test = df_filterd[-test_size:]\ndf_train.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"      User  Rating  Movie\n0   509987     3.0    811\n1   581517     3.0   1180\n2  1320147     5.0   3860\n3  1170130     5.0   1144\n4   337793     4.0   2866","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Rating</th>\n      <th>Movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>509987</td>\n      <td>3.0</td>\n      <td>811</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>581517</td>\n      <td>3.0</td>\n      <td>1180</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1320147</td>\n      <td>5.0</td>\n      <td>3860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1170130</td>\n      <td>5.0</td>\n      <td>1144</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>337793</td>\n      <td>4.0</td>\n      <td>2866</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"            User  Rating  Movie\n4078032  1191964     4.0   4157\n4078033  1889384     3.0   3725\n4078034  1056238     3.0   3320\n4078035   253434     5.0   1174\n4078036   322078     4.0   2782","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Rating</th>\n      <th>Movie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4078032</th>\n      <td>1191964</td>\n      <td>4.0</td>\n      <td>4157</td>\n    </tr>\n    <tr>\n      <th>4078033</th>\n      <td>1889384</td>\n      <td>3.0</td>\n      <td>3725</td>\n    </tr>\n    <tr>\n      <th>4078034</th>\n      <td>1056238</td>\n      <td>3.0</td>\n      <td>3320</td>\n    </tr>\n    <tr>\n      <th>4078035</th>\n      <td>253434</td>\n      <td>5.0</td>\n      <td>1174</td>\n    </tr>\n    <tr>\n      <th>4078036</th>\n      <td>322078</td>\n      <td>4.0</td>\n      <td>2782</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Next we want to create a large, sparse matrix to facilitate the recommendation algorithms that we will be building, which consists of 20M users by 490+ movies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a user-movie matrix with empty values\ndf_p = df_train.pivot_table(index='User', columns='Movie', values='Rating')\nprint('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\ndf_p.head()","execution_count":8,"outputs":[{"output_type":"stream","text":"Shape User-Movie-Matrix:\t(20828, 491)\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"Movie    8     18    28    30    58    77    83    97    108   111   ...  \\\nUser                                                                 ...   \n1000079   NaN   NaN   2.0   4.0   NaN   NaN   3.0   NaN   NaN   NaN  ...   \n1000192   NaN   NaN   2.0   4.0   3.0   2.0   3.0   NaN   NaN   NaN  ...   \n1000301   NaN   4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n1000387   NaN   NaN   4.0   NaN   2.0   4.0   NaN   NaN   2.0   NaN  ...   \n1000410   NaN   4.0   NaN   4.0   NaN   NaN   NaN   NaN   NaN   3.0  ...   \n\nMovie    4392  4393  4402  4418  4420  4432  4472  4479  4488  4490  \nUser                                                                 \n1000079   NaN   NaN   NaN   NaN   3.0   3.0   3.0   4.0   2.0   NaN  \n1000192   NaN   4.0   NaN   NaN   NaN   4.0   NaN   5.0   NaN   NaN  \n1000301   4.0   NaN   3.0   NaN   NaN   3.0   4.0   NaN   4.0   NaN  \n1000387   4.0   2.0   2.0   4.0   NaN   3.0   2.0   NaN   2.0   NaN  \n1000410   NaN   3.0   3.0   NaN   NaN   4.0   4.0   4.0   3.0   3.0  \n\n[5 rows x 491 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Movie</th>\n      <th>8</th>\n      <th>18</th>\n      <th>28</th>\n      <th>30</th>\n      <th>58</th>\n      <th>77</th>\n      <th>83</th>\n      <th>97</th>\n      <th>108</th>\n      <th>111</th>\n      <th>...</th>\n      <th>4392</th>\n      <th>4393</th>\n      <th>4402</th>\n      <th>4418</th>\n      <th>4420</th>\n      <th>4432</th>\n      <th>4472</th>\n      <th>4479</th>\n      <th>4488</th>\n      <th>4490</th>\n    </tr>\n    <tr>\n      <th>User</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000079</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1000192</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1000301</th>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1000387</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1000410</th>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 491 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Popularity-Based Recommendation\n\nComputing the mean rating for all movies creates a ranking. The recommendation will be the same for all users and can be used if there is no information on the user. Variations of this approach can be separate rankings for each country/year/gender/... and to use them individually to recommend movies/items to the user. However,using the rating of a movie alone is biased and favours movies with fewer ratings, since large numbers of ratings tend to be less extreme in its mean ratings. To tackle the problem of the unstable mean with few ratings e.g. IDMb uses a weighted rating. Many good ratings outweigh few in this algorithm.\n\nQuestions\n* why dont we use the original count and rating? because we only want to include active users\n* how do we deal with NaN values? we dont, we just count those without NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of minimum votes to be considered\nm = 1000\nn = 10\nC = df_p.stack().mean() # Mean rating for all movies\nR = df_p.mean(axis=0).values # Mean rating for all movies separately\nv = df_p.count().values # Rating count for all movies separately\nweighted_score = (v/ (v+m) *R) + (m/ (v+m) *C)\nweighted_ranking = np.argsort(weighted_score)[::-1]\nweighted_score = np.sort(weighted_score)[::-1]\nweighted_movie_ids = df_p.columns[weighted_ranking]\nratings_count = df_p.count(axis=0).rename('Rating-Count').to_frame()\n\n# Join labels and predictions\ndf_prediction = df_test.set_index('Movie').join(pd.DataFrame(weighted_score, index=weighted_movie_ids, columns=['Prediction']))[['Rating', 'Prediction']]\ny_true = df_prediction['Rating']\ny_pred = df_prediction['Prediction']\nrmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n\n# Create DataFrame for plotting\ndf_plot = pd.DataFrame(weighted_score[:n], columns=['Rating'])\ndf_plot.index = weighted_movie_ids[:10]\nranking_weighted_rating = df_plot.join(ratings_count).join(movie_titles)\n\n\n# Create trace\ntrace = go.Bar(x = ranking_weighted_rating['Rating'],\n               text = ranking_weighted_rating['Name'].astype(str) +': '+ ranking_weighted_rating['Rating-Count'].astype(str) + ' Ratings',\n               textposition = 'outside',\n               textfont = dict(color = '#000000'),\n               orientation = 'h',\n               y = list(range(1, n+1)),\n               marker = dict(color = '#db0000'))\n# Create layout\nlayout = dict(title = 'Ranking Of Top {} Weighted-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n              xaxis = dict(title = 'Weighted Rating',\n                          range = (4.15, 4.6)),\n              yaxis = dict(title = 'Movie'))\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"config":{"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly","showLink":false},"data":[{"marker":{"color":"#db0000"},"orientation":"h","text":["Lord of the Rings: The Fellowship of the Ring: 18439 Ratings","Finding Nemo (Widescreen): 17395 Ratings","The Sixth Sense: 19150 Ratings","The Silence of the Lambs: 18808 Ratings","The Godfather: 13116 Ratings","The Simpsons: Season 3: 6168 Ratings","Braveheart: 17998 Ratings","The Simpsons: Treehouse of Horror: 4989 Ratings","Family Guy: Freakin' Sweet Collection: 2805 Ratings","Batman Begins: 9731 Ratings"],"textfont":{"color":"#000000"},"textposition":"outside","type":"bar","x":[4.379356992145393,4.323746701294608,4.292869507211627,4.284901078872895,4.2682998420455025,4.2641351242067955,4.221250687983699,4.2089364785964785,4.19193707498405,4.190133311929393],"y":[1,2,3,4,5,6,7,8,9,10]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Ranking Of Top 10 Weighted-Movie-Ratings: 0.9930 RMSE"},"xaxis":{"range":[4.15,4.6],"title":{"text":"Weighted Rating"}},"yaxis":{"title":{"text":"Movie"}}}},"text/html":"<div>                            <div id=\"a07d8a54-3538-4c7f-9f3a-d9c9f72d7e4f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a07d8a54-3538-4c7f-9f3a-d9c9f72d7e4f\")) {                    Plotly.newPlot(                        \"a07d8a54-3538-4c7f-9f3a-d9c9f72d7e4f\",                        [{\"marker\": {\"color\": \"#db0000\"}, \"orientation\": \"h\", \"text\": [\"Lord of the Rings: The Fellowship of the Ring: 18439 Ratings\", \"Finding Nemo (Widescreen): 17395 Ratings\", \"The Sixth Sense: 19150 Ratings\", \"The Silence of the Lambs: 18808 Ratings\", \"The Godfather: 13116 Ratings\", \"The Simpsons: Season 3: 6168 Ratings\", \"Braveheart: 17998 Ratings\", \"The Simpsons: Treehouse of Horror: 4989 Ratings\", \"Family Guy: Freakin' Sweet Collection: 2805 Ratings\", \"Batman Begins: 9731 Ratings\"], \"textfont\": {\"color\": \"#000000\"}, \"textposition\": \"outside\", \"type\": \"bar\", \"x\": [4.379356992145393, 4.323746701294608, 4.292869507211627, 4.284901078872895, 4.2682998420455025, 4.2641351242067955, 4.221250687983699, 4.2089364785964785, 4.19193707498405, 4.190133311929393], \"y\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Ranking Of Top 10 Weighted-Movie-Ratings: 0.9930 RMSE\"}, \"xaxis\": {\"range\": [4.15, 4.6], \"title\": {\"text\": \"Weighted Rating\"}}, \"yaxis\": {\"title\": {\"text\": \"Movie\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('a07d8a54-3538-4c7f-9f3a-d9c9f72d7e4f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ranking_weighted_rating.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"         Rating  Rating-Count    Year  \\\nMovie                                   \n2452   4.379357         18439  2001.0   \n3962   4.323747         17395  2003.0   \n4306   4.292870         19150  1999.0   \n2862   4.284901         18808  1991.0   \n3290   4.268300         13116  1974.0   \n\n                                                Name  \nMovie                                                 \n2452   Lord of the Rings: The Fellowship of the Ring  \n3962                       Finding Nemo (Widescreen)  \n4306                                 The Sixth Sense  \n2862                        The Silence of the Lambs  \n3290                                   The Godfather  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rating</th>\n      <th>Rating-Count</th>\n      <th>Year</th>\n      <th>Name</th>\n    </tr>\n    <tr>\n      <th>Movie</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2452</th>\n      <td>4.379357</td>\n      <td>18439</td>\n      <td>2001.0</td>\n      <td>Lord of the Rings: The Fellowship of the Ring</td>\n    </tr>\n    <tr>\n      <th>3962</th>\n      <td>4.323747</td>\n      <td>17395</td>\n      <td>2003.0</td>\n      <td>Finding Nemo (Widescreen)</td>\n    </tr>\n    <tr>\n      <th>4306</th>\n      <td>4.292870</td>\n      <td>19150</td>\n      <td>1999.0</td>\n      <td>The Sixth Sense</td>\n    </tr>\n    <tr>\n      <th>2862</th>\n      <td>4.284901</td>\n      <td>18808</td>\n      <td>1991.0</td>\n      <td>The Silence of the Lambs</td>\n    </tr>\n    <tr>\n      <th>3290</th>\n      <td>4.268300</td>\n      <td>13116</td>\n      <td>1974.0</td>\n      <td>The Godfather</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#movie_metadata = pd.read_csv('../input/the-movies-dataset/movies_metadata.csv', low_memory=False)\n#movie_metadata.head()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_plot, weighted_ranking, weighted_score, weighted_movie_ids, ratings_count","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Content-Based: User Similarity\n\n\"Other users are also watching\"\n\nThis recommendation strategy recommends movies that other similar users are also interested in. \n\nInterpreting each row of the matrix as a vector, a similarity between all user-vectors can be computed. This enables us to find all similar users and to work on user-specific recommendations. Recommending high rated movies of similar users to a specific user seems reasonable.\n\nSince there are still empty values left in the matrix, we have to use a reliable way to impute a decent value. A simple first approach is to fill in the mean of each user into the empty values.\n\nAfterwards the ratings of all similar users will be weighted with their similarity score and the mean will be computed. Filtering for the unrated movies of a user reveals the best recommendations.\n\nYou can easily adapt this process to find similar items by computing the item-item similarity the same way. Since the matrix is mostly sparse and there are more users than items, this could be better for the RMSE score."},{"metadata":{"trusted":true},"cell_type":"code","source":"user_index = 0\nn_recommendation = 100\nn_plot = 10\ndf_p_imputed = df_p.T.fillna(df_p.mean(axis=1)).T # Fill in missing values with mean user ratings\ndf_p_imputed.head()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"Movie        8         18        28        30        58        77        83    \\\nUser                                                                            \n1000079  2.852071  2.852071  2.000000  4.000000  2.852071  2.852071  3.000000   \n1000192  3.135246  3.135246  2.000000  4.000000  3.000000  2.000000  3.000000   \n1000301  3.361111  4.000000  3.000000  3.361111  3.361111  3.361111  3.361111   \n1000387  2.878049  2.878049  4.000000  2.878049  2.000000  4.000000  2.878049   \n1000410  3.323671  4.000000  3.323671  4.000000  3.323671  3.323671  3.323671   \n\nMovie        97        108       111   ...      4392      4393      4402  \\\nUser                                   ...                                 \n1000079  2.852071  2.852071  2.852071  ...  2.852071  2.852071  2.852071   \n1000192  3.135246  3.135246  3.135246  ...  3.135246  4.000000  3.135246   \n1000301  3.361111  3.361111  3.361111  ...  4.000000  3.361111  3.000000   \n1000387  2.878049  2.000000  2.878049  ...  4.000000  2.000000  2.000000   \n1000410  3.323671  3.323671  3.000000  ...  3.323671  3.000000  3.000000   \n\nMovie        4418      4420  4432      4472      4479      4488      4490  \nUser                                                                       \n1000079  2.852071  3.000000   3.0  3.000000  4.000000  2.000000  2.852071  \n1000192  3.135246  3.135246   4.0  3.135246  5.000000  3.135246  3.135246  \n1000301  3.361111  3.361111   3.0  4.000000  3.361111  4.000000  3.361111  \n1000387  4.000000  2.878049   3.0  2.000000  2.878049  2.000000  2.878049  \n1000410  3.323671  3.323671   4.0  4.000000  4.000000  3.000000  3.000000  \n\n[5 rows x 491 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Movie</th>\n      <th>8</th>\n      <th>18</th>\n      <th>28</th>\n      <th>30</th>\n      <th>58</th>\n      <th>77</th>\n      <th>83</th>\n      <th>97</th>\n      <th>108</th>\n      <th>111</th>\n      <th>...</th>\n      <th>4392</th>\n      <th>4393</th>\n      <th>4402</th>\n      <th>4418</th>\n      <th>4420</th>\n      <th>4432</th>\n      <th>4472</th>\n      <th>4479</th>\n      <th>4488</th>\n      <th>4490</th>\n    </tr>\n    <tr>\n      <th>User</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000079</th>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>3.000000</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>...</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>2.852071</td>\n      <td>3.000000</td>\n      <td>3.0</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>2.852071</td>\n    </tr>\n    <tr>\n      <th>1000192</th>\n      <td>3.135246</td>\n      <td>3.135246</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.135246</td>\n      <td>3.135246</td>\n      <td>3.135246</td>\n      <td>...</td>\n      <td>3.135246</td>\n      <td>4.000000</td>\n      <td>3.135246</td>\n      <td>3.135246</td>\n      <td>3.135246</td>\n      <td>4.0</td>\n      <td>3.135246</td>\n      <td>5.000000</td>\n      <td>3.135246</td>\n      <td>3.135246</td>\n    </tr>\n    <tr>\n      <th>1000301</th>\n      <td>3.361111</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>3.361111</td>\n      <td>3.000000</td>\n      <td>3.361111</td>\n      <td>3.361111</td>\n      <td>3.0</td>\n      <td>4.000000</td>\n      <td>3.361111</td>\n      <td>4.000000</td>\n      <td>3.361111</td>\n    </tr>\n    <tr>\n      <th>1000387</th>\n      <td>2.878049</td>\n      <td>2.878049</td>\n      <td>4.000000</td>\n      <td>2.878049</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>2.878049</td>\n      <td>2.878049</td>\n      <td>2.000000</td>\n      <td>2.878049</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>2.878049</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>2.878049</td>\n      <td>2.000000</td>\n      <td>2.878049</td>\n    </tr>\n    <tr>\n      <th>1000410</th>\n      <td>3.323671</td>\n      <td>4.000000</td>\n      <td>3.323671</td>\n      <td>4.000000</td>\n      <td>3.323671</td>\n      <td>3.323671</td>\n      <td>3.323671</td>\n      <td>3.323671</td>\n      <td>3.323671</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>3.323671</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.323671</td>\n      <td>3.323671</td>\n      <td>4.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 491 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute similarity between all users and remove self-similarity\nsimilarity = cosine_similarity(df_p_imputed.values)\nsimilarity -= np.eye(similarity.shape[0])\nprint(np.shape(similarity))\n# similarity # An NxN matrix of similarity score for each user","execution_count":14,"outputs":[{"output_type":"stream","text":"(20828, 20828)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_movies_of_top_n_similar_users(similarity, user_index=0, n_recommendation=100):\n    # Sort similar users by index and score\n    similar_user_index = np.argsort(similarity[user_index])[::-1]\n    similar_user_score = np.sort(similarity[user_index])[::-1]\n\n    # Get movies that user has not rated / watched\n    unrated_movies = df_p.iloc[user_index][df_p.iloc[user_index].isna()].index\n\n    # Weight ratings of the top n most similar users with their rating and compute the mean for each movie\n    mean_movie_recommendations = (df_p_imputed.iloc[similar_user_index[:n_recommendation]].T * similar_user_score[:n_recommendation]).T.mean(axis=0)\n\n    # Filter for unrated movies and sort results\n    best_movie_recommendations = mean_movie_recommendations[unrated_movies].sort_values(ascending=False).to_frame().join(movie_titles)\n\n    return best_movie_recommendations\n\nget_movies_of_top_n_similar_users(similarity)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"              0    Year                       Name\nMovie                                             \n3938   4.498563  2004.0                    Shrek 2\n4306   4.496051  1999.0            The Sixth Sense\n3962   4.443040  2003.0  Finding Nemo (Widescreen)\n1144   4.406760  1991.0       Fried Green Tomatoes\n191    4.405994  2003.0           X2: X-Men United\n...         ...     ...                        ...\n1289   4.094712  1990.0     Look Who's Talking Too\n3385   4.085870  2002.0              28 Days Later\n1267   4.082044  2001.0             Dr. Dolittle 2\n3254   3.993826  2003.0                  Daredevil\n3151   3.992325  2004.0          Napoleon Dynamite\n\n[322 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>Year</th>\n      <th>Name</th>\n    </tr>\n    <tr>\n      <th>Movie</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3938</th>\n      <td>4.498563</td>\n      <td>2004.0</td>\n      <td>Shrek 2</td>\n    </tr>\n    <tr>\n      <th>4306</th>\n      <td>4.496051</td>\n      <td>1999.0</td>\n      <td>The Sixth Sense</td>\n    </tr>\n    <tr>\n      <th>3962</th>\n      <td>4.443040</td>\n      <td>2003.0</td>\n      <td>Finding Nemo (Widescreen)</td>\n    </tr>\n    <tr>\n      <th>1144</th>\n      <td>4.406760</td>\n      <td>1991.0</td>\n      <td>Fried Green Tomatoes</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>4.405994</td>\n      <td>2003.0</td>\n      <td>X2: X-Men United</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1289</th>\n      <td>4.094712</td>\n      <td>1990.0</td>\n      <td>Look Who's Talking Too</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>4.085870</td>\n      <td>2002.0</td>\n      <td>28 Days Later</td>\n    </tr>\n    <tr>\n      <th>1267</th>\n      <td>4.082044</td>\n      <td>2001.0</td>\n      <td>Dr. Dolittle 2</td>\n    </tr>\n    <tr>\n      <th>3254</th>\n      <td>3.993826</td>\n      <td>2003.0</td>\n      <td>Daredevil</td>\n    </tr>\n    <tr>\n      <th>3151</th>\n      <td>3.992325</td>\n      <td>2004.0</td>\n      <td>Napoleon Dynamite</td>\n    </tr>\n  </tbody>\n</table>\n<p>322 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clear up ram\ndel similarity","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Content-Based: TFIDF Movie Metadata Similarity\n\n\"Because you watched this\" \n\nIf there is no historical data for a user or there is reliable metadata for each movie, it can be useful to compare the metadata of the movies to find similar ones.\nIn this approch I will use the movie description to create a TFIDF-matrix, which counts and weights words in all descriptions, and compute a cosine similarity between all of those sparse text-vectors. This can easily be extended to more or different features if you like.\nUnfortunately it is impossible for this model to compute a RMSE score, since the model does not recommend the movies directly.\nIn this way it is possible to find movies closly related to each other, but it is hard to find movies of different genres/categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_n_similar_movies(movie_metadata, n=10, movie='Batman Begins'):\n    # Create tf-idf matrix for text comparison and compute cosine similarity between all movies\n    tfidf = TfidfVectorizer(stop_words='english', max_features=100)\n    tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'].dropna())\n    similarity = cosine_similarity(tfidf_matrix)\n    similarity -= np.eye(similarity.shape[0])\n\n    # Get index of movie and get titles of similar movies\n    index = movie_metadata.reset_index(drop=True)[movie_metadata.index==movie].index[0]\n    similar_movies_index = np.argsort(similarity[index])[::-1][:n]\n    similar_movies_score = np.sort(similarity[index])[::-1][:n]\n    similar_movie_titles = movie_metadata.iloc[similar_movies_index].index\n    del similarity, tfidf_matrix\n    \n    return similar_movie_titles\n\nget_top_n_similar_movies(movie_metadata)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"Index(['Stir Crazy', 'Bound for Glory', 'All of My Heart', 'Import/Export',\n       'FearDotCom', 'Mr. Blandings Builds His Dream House',\n       'Hunt for the Wilderpeople', 'As Good as It Gets',\n       'The Internet's Own Boy: The Story of Aaron Swartz',\n       ''Tis the Season for Love'],\n      dtype='object', name='original_title')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Collaborative Filtering: Matrix Factorization with Gradient Descent\n\nThe user-movie rating matrix is high dimensional and sparse, therefore I am going to reduce the dimensionality to represent the data in a dense form.\nUsing matrix factorisation a large matrix can be estimated/decomposed into two long but slim matrices. With gradient descent it is possible to adjust these matrices to represent the given ratings. The gradient descent algorithm finds latent variables which represent the underlying structure of the dataset. Afterwards these latent variables can be used to reconstruct the original matrix and to predict the missing ratings for each user.\nIn this case the model has not been trained to convergence and is not hyperparameter optimized."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create user- & movie-id mapping\nuser_id_mapping = {id:i for i, id in enumerate(df_filterd['User'].unique())}\nmovie_id_mapping = {id:i for i, id in enumerate(df_filterd['Movie'].unique())}\n\n\n# Create correctly mapped train- & testset\ntrain_user_data = df_train['User'].map(user_id_mapping)\ntrain_movie_data = df_train['Movie'].map(movie_id_mapping)\n\ntest_user_data = df_test['User'].map(user_id_mapping)\ntest_movie_data = df_test['Movie'].map(movie_id_mapping)\n\n\n# Get input variable-sizes\nusers = len(user_id_mapping)\nmovies = len(movie_id_mapping)\nembedding_size = 10\n\n\n##### Create model\n# Set input layers\nuser_id_input = Input(shape=[1], name='user')\nmovie_id_input = Input(shape=[1], name='movie')\n\n# Create embedding layers for users and movies\nuser_embedding = Embedding(output_dim=embedding_size, \n                           input_dim=users,\n                           input_length=1, \n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=embedding_size, \n                            input_dim=movies,\n                            input_length=1, \n                            name='item_embedding')(movie_id_input)\n\n# Reshape the embedding layers\nuser_vector = Reshape([embedding_size])(user_embedding)\nmovie_vector = Reshape([embedding_size])(movie_embedding)\n\n# Compute dot-product of reshaped embedding layers as prediction\ny = Dot(1, normalize=False)([user_vector, movie_vector])\n\n# Setup model\nmodel = Model(inputs=[user_id_input, movie_id_input], outputs=y)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Fit model\nmodel.fit([train_user_data, train_movie_data],\n          df_train['Rating'],\n          batch_size=256, \n          epochs=1,\n          validation_split=0.1,\n          shuffle=True)\n\n# Test model\ny_pred = model.predict([test_user_data, test_movie_data])\ny_true = df_test['Rating'].values\n\n#  Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Matrix-Factorization: {:.4f} RMSE'.format(rmse))","execution_count":18,"outputs":[{"output_type":"stream","text":"14337/14337 [==============================] - 36s 3ms/step - loss: 2.1926 - val_loss: 0.8562\n\n\nTesting Result With Keras Matrix-Factorization: 0.9275 RMSE\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Matrix Factorization: Deep Learning using various MetaData\n\nWith its embedding layers this is similar to the matrix factorization approach above, but instead of using a fixed dot-product as recommendation we will utilize some dense layers so the network can find better combinations. One advantage of deep learning models is, that movie-metadata can easily be added to the model.\n\nI will tf-idf transform the short description of all movies to a sparse vector. The model will learn to reduce the dimensionality of this vector and how to combine metadata with the embedding of the user-id and the movie-id. In this way you can add any additional metadata to your own recommender.\n\nThese kind of hybrid systems can learn how to reduce the impact of the cold start problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"user_id_mapping = {id: i for i, id in enumerate(df['User'].unique())}\nmovie_id_mapping = {id: i for i, id in enumerate(df['Movie'].unique())}\ndf['User'] = df['User'].map(user_id_mapping)\ndf['Movie'] = df['Movie'].map(movie_id_mapping)\n\n# Preprocess metadata\ntmp_metadata = movie_metadata.copy()\ntmp_metadata.index = tmp_metadata.index.str.lower()\n\n# Preprocess titles\ntmp_titles = movie_titles.drop('Year', axis=1).copy()\ntmp_titles = tmp_titles.reset_index().set_index('Name')\ntmp_titles.index = tmp_titles.index.str.lower()\n\n# Combine titles and metadata\ndf_id_descriptions = tmp_titles.join(tmp_metadata).dropna().set_index('Id')\ndf_id_descriptions['overview'] = df_id_descriptions['overview'].str.lower()\ndel tmp_metadata,tmp_titles\ndf_id_descriptions.head()\n","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                                                overview\nId                                                      \n7756   an ethical baltimore defense lawyer disgusted ...\n2945   a hollywood songwriter goes through a mid-life...\n14249  a hollywood songwriter goes through a mid-life...\n3463   bianca, a tenth grader, has never gone on a da...\n11972  based on the real-life richard speck murders, ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overview</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7756</th>\n      <td>an ethical baltimore defense lawyer disgusted ...</td>\n    </tr>\n    <tr>\n      <th>2945</th>\n      <td>a hollywood songwriter goes through a mid-life...</td>\n    </tr>\n    <tr>\n      <th>14249</th>\n      <td>a hollywood songwriter goes through a mid-life...</td>\n    </tr>\n    <tr>\n      <th>3463</th>\n      <td>bianca, a tenth grader, has never gone on a da...</td>\n    </tr>\n    <tr>\n      <th>11972</th>\n      <td>based on the real-life richard speck murders, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter all ratings with metadata, split into training and testing sets\ndf_hybrid = df.drop('Date', axis=1).set_index('Movie').join(df_id_descriptions).dropna().drop('overview', axis=1).reset_index().rename({'index':'Movie'}, axis=1)\nn = 100000\ndf_hybrid = df_hybrid.sample(frac=1).reset_index(drop=True)\ndf_hybrid_train = df_hybrid[:1500000]\ndf_hybrid_test = df_hybrid[-n:]\n\n\n# Create tf-idf matrix for text comparison\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_hybrid = tfidf.fit_transform(df_id_descriptions['overview'])\nmapping = {id:i for i, id in enumerate(df_id_descriptions.index)}\n\ntrain_tfidf = []\n# Iterate over all movie-ids and save the tfidf-vector\nfor id in df_hybrid_train['Movie'].values:\n    index = mapping[id]\n    train_tfidf.append(tfidf_hybrid[index])\n    \ntest_tfidf = []\n# Iterate over all movie-ids and save the tfidf-vector\nfor id in df_hybrid_test['Movie'].values:\n    index = mapping[id]\n    test_tfidf.append(tfidf_hybrid[index])\n\n\n# Stack the sparse matrices\ntrain_tfidf = vstack(train_tfidf)\ntest_tfidf = vstack(test_tfidf)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Setup the network variables\nuser_embed = 10\nmovie_embed = 10\n\nuser_id_input = Input(shape=[1], name='user') # Create two input layers\nmovie_id_input = Input(shape=[1], name='movie')\ntfidf_input = Input(shape=[24144], name='tfidf', sparse=True)\n\n# Create separate embeddings for users and movies\nuser_embedding = Embedding(output_dim=user_embed,\n                           input_dim=len(user_id_mapping),\n                           input_length=1,\n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=movie_embed,\n                            input_dim=len(movie_id_mapping),\n                            input_length=1,\n                            name='movie_embedding')(movie_id_input)\n\n# Create 2 layers, reshape and concatenate them\ntfidf_vectors = Dense(128, activation='relu')(tfidf_input)\ntfidf_vectors = Dense(32, activation='relu')(tfidf_vectors)\nuser_vectors = Reshape([user_embed])(user_embedding)\nmovie_vectors = Reshape([movie_embed])(movie_embedding)\nboth = Concatenate()([user_vectors, movie_vectors, tfidf_vectors])\ndense = Dense(512, activation='relu')(both)\ndense = Dropout(0.2)(dense)\noutput = Dense(1)(dense)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and compile model\nmodel = Model(inputs=[user_id_input, movie_id_input, tfidf_input], outputs=output)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Train and test the network\nmodel.fit([df_hybrid_train['User'], df_hybrid_train['Movie'], train_tfidf],\n          df_hybrid_train['Rating'],\n          batch_size=1024, \n          epochs=2,\n          validation_split=0.1,\n          shuffle=True)\n\ny_pred = model.predict([df_hybrid_test['User'], df_hybrid_test['Movie'], test_tfidf])\ny_true = df_hybrid_test['Rating'].values\n\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Hybrid Deep Learning: {:.4f} RMSE'.format(rmse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Surprise Library\n\nThe surprise library was built for creating and analyzing recommender systems.\nIt has to be mentioned that most of the built-in algorithms use some kind of the above approches. I am going to compare these algorithms to each other in this section using 5-fold crossvalidation. Since the algorithms and the dataset have a large memoryfootprint the comparison will be executed on a subsampled dataset which is not comparable to the above models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run 5-fold cross-validation on the famous SVD algorithm \nmovies = sp.Dataset.load_from_df(df_filterd[['User', 'Movie', 'Rating']].sample(50000), sp.Reader())\nmovies","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"<surprise.dataset.DatasetAutoFolds at 0x7feb843d7350>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"First lets test out the famous [SVD algorithm](http://https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD ) by Simon Funk, used in the Netflix Prize Competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_validate(algo=sp.SVD(), data=movies, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import accuracy\nfrom surprise import Dataset\nfrom surprise.model_selection import train_test_split, KFold\nfrom collections import defaultdict\n\ndef get_top_n(predictions, n=10):\n    # Map the predictions to each user.\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # sort predictions for each user and retrieve the k highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n\n\n# Train SVD algorithm on movielens dataset.\nmovies = Dataset.load_builtin('ml-100k')\ntrain_data, test_data = train_test_split(movies, test_size=0.2)\nmodel = sp.SVD()\npredictions = model.fit(train_data).test(test_data)\naccuracy.rmse(predictions)\nmodel.predict(uid=str(196), iid=str(302)) # predict a rating that user(i) would give item(j)\ntop_n = get_top_n(predictions, n=10)\nfor uid, user_ratings in top_n.items():\n    print(uid, [iid for (iid, _) in user_ratings])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision@K and Recall@K"},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision_recall_at_k(predictions, k=10, threshold=3.5):\n    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n\n    precisions, recalls = {}, {} # Map the predictions to each user.\n    user_est_true = defaultdict(list)\n    for uid, _, true_r, est, _ in predictions:\n        user_est_true[uid].append((est, true_r))\n\n    for uid, user_ratings in user_est_true.items():\n        # Sort user ratings by estimated value\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n\n        # Count number of relevant items and recommended items in top k\n        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n\n        # Number of relevant and recommended items in top k\n        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n                              for (est, true_r) in user_ratings[:k])\n\n        # Precision@K: Proportion of recommended items that are relevant\n        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n\n        # Recall@K: Proportion of relevant items that are recommended\n        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n\n    return precisions, recalls\n\nfor trainset, testset in KFold(n_splits=5).split(movies):\n    model.fit(trainset)\n    predictions = model.test(testset)\n    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n\n    # Precision and recall can then be averaged over all users\n    print(sum(prec for prec in precisions.values()) / len(precisions))\n    print(sum(rec for rec in recalls.values()) / len(recalls))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, lets try a [K Nearest Neighbours](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline) basic collaborative filtering algorithm taking into account a baseline rating."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run 5 fold validation on KNN approach using baseline\ncross_validate(algo=sp.KNNBaseline(), data=movies, measures=['RMSE', 'MAE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import io \n\ndef read_item_names():\n    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n    mappings to convert raw ids into movie names and movie names into raw ids.\n    \"\"\"\n    file_name = sp.get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n    rid_to_name = {}\n    name_to_rid = {}\n    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n        for line in f:\n            line = line.split('|')\n            rid_to_name[line[0]] = line[1]\n            name_to_rid[line[1]] = line[0]\n\n    return rid_to_name, name_to_rid\n\n# Train the KNN algortihm to compute the similarities between items\ndata = Dataset.load_builtin('ml-100k')\ntrainset = data.build_full_trainset()\nsim_options = {'name': 'pearson_baseline', 'user_based': False}\nalgo = sp.KNNBaseline(sim_options=sim_options)\nalgo.fit(trainset)\n\n# Read the mappings raw id <-> movie name\nrid_to_name, name_to_rid = read_item_names()\ntoy_story_raw_id = name_to_rid['Toy Story (1995)']\ntoy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n\n# Retrieve inner ids of the nearest neighbors of Toy Story.\ntoy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n\n# Convert inner ids of the neighbors into names.\ntoy_story_neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in toy_story_neighbors)\ntoy_story_neighbors = (rid_to_name[rid] for rid in toy_story_neighbors)\n\nprint()\nprint('The 10 nearest neighbors of Toy Story are:')\nfor movie in toy_story_neighbors:\n    print(movie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}